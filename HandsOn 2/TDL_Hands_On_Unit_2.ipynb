{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDL Hands On Unit 2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Linear Kernel in SVM (Hard Margin Classifier)"
      ],
      "metadata": {
        "id": "8BEnP-q16-_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bankdata = pd.read_csv(\"bill_authentication.csv\")\n",
        "print(\"Dimension of dataset -:\", bankdata.shape)\n",
        "print(\"\\n\")\n",
        "print(\"Top 5 rows in dataset\\n\", bankdata.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "X = bankdata.drop('Class', axis=1)\n",
        "y = bankdata['Class']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='linear')\n",
        "svclassifier.fit(X_train, y_train)\n",
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cYlqxcc7BYU",
        "outputId": "5cd3a5b9-e962-48f3-ca49-bd12ba5fd3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of dataset -: (1372, 5)\n",
            "\n",
            "\n",
            "Top 5 rows in dataset\n",
            "    Variance  Skewness  Curtosis  Entropy  Class\n",
            "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
            "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
            "2   3.86600   -2.6383    1.9242  0.10645      0\n",
            "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
            "4   0.32924   -4.4552    4.5718 -0.98880      0\n",
            "\n",
            "\n",
            "[[142   2]\n",
            " [  1 130]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       144\n",
            "           1       0.98      0.99      0.99       131\n",
            "\n",
            "    accuracy                           0.99       275\n",
            "   macro avg       0.99      0.99      0.99       275\n",
            "weighted avg       0.99      0.99      0.99       275\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial Kernel (Soft Margin)"
      ],
      "metadata": {
        "id": "uJTLM7utjqtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class'] # Assign colum names to the dataset\n",
        "irisdata = pd.read_csv(url, names=colnames) # Read dataset to pandas dataframe\n",
        "\n",
        "X = irisdata.drop('Class', axis=1)\n",
        "y = irisdata['Class']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "#svclassifier = SVC(kernel='poly', degree=8)\n",
        "#svclassifier = SVC(kernel='linear')\n",
        "#svclassifier = SVC(kernel='rbf')\n",
        "svclassifier = SVC(kernel='sigmoid')\n",
        "\n",
        "svclassifier.fit(X_train, y_train)\n",
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"Confusion Matrix\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\n\")\n",
        "print(\"Classification Report\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw42br_Hju3-",
        "outputId": "aaa926fd-5c03-4eb6-fb24-deea03c8d5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            " [[ 8  0  0]\n",
            " [13  0  0]\n",
            " [ 9  0  0]]\n",
            "\n",
            "\n",
            "Classification Report\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       0.27      1.00      0.42         8\n",
            "Iris-versicolor       0.00      0.00      0.00        13\n",
            " Iris-virginica       0.00      0.00      0.00         9\n",
            "\n",
            "       accuracy                           0.27        30\n",
            "      macro avg       0.09      0.33      0.14        30\n",
            "   weighted avg       0.07      0.27      0.11        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning Hyperparameters C and Gamma (Multiclass Classification)"
      ],
      "metadata": {
        "id": "97S39jXnrNAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm, datasets\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=101)\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
        "#rbf = svm.SVC(kernel='rbf', gamma=0.8, C=0.15).fit(X_train, y_train)\n",
        "#poly = svm.SVC(kernel='poly', degree=3, C=100).fit(X_train, y_train)\n",
        "poly = svm.SVC(kernel='poly', degree=2, C=0.1).fit(X_train, y_train) #73.33\n",
        "\n",
        "poly_pred = poly.predict(X_test)\n",
        "rbf_pred = rbf.predict(X_test)\n",
        "\n",
        "\n",
        "poly_accuracy = accuracy_score(y_test, poly_pred) # Accuracy of polynomial kernel\n",
        "poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
        "\n",
        "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
        "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n",
        "\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred) # Accuracy of RBF kernel\n",
        "rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
        "print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWmJBCgfrOpl",
        "outputId": "b02190c1-42a1-4284-a6a7-188173b474e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Polynomial Kernel):  73.33\n",
            "F1 (Polynomial Kernel):  72.45\n",
            "Accuracy (RBF Kernel):  76.67\n",
            "F1 (RBF Kernel):  76.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclass classification with ANOVA kernel"
      ],
      "metadata": {
        "id": "kGic_3XqofUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n"
      ],
      "metadata": {
        "id": "VEbhgS5nojFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Classificiation using SVM"
      ],
      "metadata": {
        "id": "vCfQ3nODooeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAjNZXWse_29",
        "outputId": "a1e4deb9-4b1d-4871-ba07-813f15163379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(500) #Set Random seed\n",
        "\n",
        "Corpus = pd.read_csv(r\"corpus.csv\",encoding='latin-1') # Add the Data using pandas\n",
        "\n",
        "# Step - 1: Data Pre-processing - This will help in getting better results through the classification algorithms\n",
        "# Step - 1a : Remove blank rows if any.\n",
        "Corpus['text'].dropna(inplace=True)\n",
        "\n",
        "\n",
        "# Step - 1b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
        "Corpus['text'] = [entry.lower() for entry in Corpus['text']]\n",
        "\n",
        "\n",
        "# Step - 1c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "Corpus['text']= [word_tokenize(entry) for entry in Corpus['text']]\n",
        "\n",
        "\n",
        "# Step - 1d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(Corpus['text']):\n",
        "  Final_words = [] # Declaring Empty List to store the words that follow the rules for this step\n",
        "  word_Lemmatized = WordNetLemmatizer() # Initializing WordNetLemmatizer()\n",
        "  for word, tag in pos_tag(entry): \n",
        "    if word not in stopwords.words('english') and word.isalpha():\n",
        "      #condition checks for Stop words and consider only alphabets\n",
        "      word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "      Final_words.append(word_Final)\n",
        "  Corpus.loc[index,'text_final'] = str(Final_words) #The final processed set of words for each iteration will be stored in 'text_final'\n",
        "#print(Corpus['text_final'].head())\n",
        "\n",
        "\n",
        "#Step - 2: Split the model into Train and Test Data set\n",
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['label'],test_size=0.3)\n",
        "\n",
        "\n",
        "# Step - 3: Label encode the target variable - This is done to transform Categorical data of string type in the data set into numerical values\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)\n",
        "\n",
        "\n",
        "# Step - 4: Vectorize the words by using TF-IDF Vectorizer - This is done to find how important a word in document is in comaprison to the corpus\n",
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(Corpus['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
        "\n",
        "\n",
        "# Step - 5: Now we can run different algorithms to classify out data check for accuracy\n",
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHlzZX2SyLfO",
        "outputId": "6d6e5546-d4f5-466a-adb6-3745bff6ed85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy Score ->  84.7\n"
          ]
        }
      ]
    }
  ]
}